<p align="center">
  <img src="public/logo.png" alt="ScrapeBI Logo" width="200">
</p>

<h1 align="center">ğŸ•·ï¸ ScrapeBI</h1>

<p align="center">
  <strong>Professional No-Code Web Scraping Platform</strong>
</p>

<p align="center">
  Extract, transform, and export web data visually â€” no coding required.
</p>

<p align="center">
  <img src="https://img.shields.io/badge/ScrapeBI-v1.0-blue?style=for-the-badge" alt="Version">
  <img src="https://img.shields.io/badge/Python-3.8+-green?style=for-the-badge&logo=python&logoColor=white" alt="Python">
  <img src="https://img.shields.io/badge/Flask-2.3.3-orange?style=for-the-badge&logo=flask&logoColor=white" alt="Flask">
  <img src="https://img.shields.io/badge/Selenium-4.15.2-red?style=for-the-badge&logo=selenium&logoColor=white" alt="Selenium">
  <img src="https://img.shields.io/badge/TailwindCSS-3.x-cyan?style=for-the-badge&logo=tailwindcss&logoColor=white" alt="TailwindCSS">
  <img src="https://img.shields.io/badge/License-MIT-lightgrey?style=for-the-badge" alt="License">
</p>

<p align="center">
  <img src="https://img.shields.io/github/stars/RaoHamzaTariq/ScrapeBI?style=flat-square" alt="GitHub stars">
  <img src="https://img.shields.io/github/forks/RaoHamzaTariq/ScrapeBI?style=flat-square" alt="GitHub forks">
  <img src="https://img.shields.io/github/issues/RaoHamzaTariq/ScrapeBI?style=flat-square" alt="GitHub issues">
  <img src="https://img.shields.io/github/last-commit/RaoHamzaTariq/ScrapeBI?style=flat-square" alt="Last commit">
  <img src="https://img.shields.io/github/repo-size/RaoHamzaTariq/ScrapeBI?style=flat-square" alt="Repository size">
  <img src="https://img.shields.io/badge/Platform-Windows%20%7C%20macOS%20%7C%20Linux-lightgrey?style=flat-square" alt="Platform">
</p>

<p align="center">
  <a href="#-features"><strong>Features</strong></a> â€¢
  <a href="#-installation"><strong>Installation</strong></a> â€¢
  <a href="#-usage"><strong>Usage</strong></a> â€¢
  <a href="#-api-reference"><strong>API</strong></a> â€¢
  <a href="#-contributing"><strong>Contributing</strong></a> â€¢
  <a href="#-support"><strong>Support</strong></a>
</p>

<p align="center">
  <img src="public/preview.png" alt="ScrapeBI Dashboard Preview" width="90%">
</p>

<p align="center">
  <sup>â­ If you find ScrapeBI useful, consider giving it a star!</sup>
</p>

---

## ğŸ“‹ Table of Contents

<details>
<summary>Click to expand</summary>

- [ğŸ“– About](#-about)
- [âœ¨ Features](#-features)
- [ğŸ¯ Use Cases](#-use-cases)
- [ğŸš€ Quick Start](#-quick-start)
- [ğŸ“¦ Installation](#-installation)
- [ğŸ’» Usage](#-usage)
- [ğŸ”Œ API Reference](#-api-reference)
- [ğŸ“š Documentation](#-documentation)
- [ğŸ—ï¸ Architecture](#ï¸-architecture)
- [ğŸ› ï¸ Configuration](#ï¸-configuration)
- [ğŸ§ª Testing](#-testing)
- [ğŸ¤ Contributing](#-contributing)
- [ğŸ“„ License](#-license)
- [ğŸ™ Acknowledgments](#-acknowledgments)
- [ğŸ“§ Support](#-support)

</details>

---

## ğŸ“– About

**ScrapeBI** is an enterprise-grade, no-code web scraping platform that empowers users to extract structured data from any website through an intuitive visual interface. Built for data analysts, researchers, marketers, and developers who need reliable web data without the complexity of traditional scraping tools.

### ğŸ¯ Problem Solved

| Traditional Scraping | With ScrapeBI |
|---------------------|---------------|
| âŒ Requires programming knowledge | âœ… No coding required |
| âŒ Fragile to website changes | âœ… Visual selector adapts easily |
| âŒ Complex setup and configuration | âœ… One-click installation |
| âŒ Limited to technical users | âœ… Accessible to everyone |
| âŒ Time-consuming development | âœ… Extract data in minutes |

### ğŸ’¡ Key Benefits

```
âš¡ Speed        â†’ Go from zero to extracted data in under 5 minutes
ğŸ¯ Precision    â†’ Visual element selection ensures accurate data extraction  
ğŸ“Š Flexibility  â†’ Export to JSON, CSV, or TXT for any workflow
ğŸ”„ Reusability  â†’ Save and reuse extraction rules across projects
ğŸ›¡ï¸ Reliability  â†’ Handles JavaScript-heavy sites with Selenium automation
```

---

## âœ¨ Features

### Core Capabilities

| Feature | Description | Benefit |
|---------|-------------|---------|
| ğŸ‘ï¸ **Visual Selector** | Point-and-click element selection | No CSS/XPath knowledge needed |
| ğŸ“‹ **Element Detection** | Auto-categorization of page elements | Instant understanding of page structure |
| ğŸ¯ **Smart Extraction** | CSS, XPath, Tag, Class, ID selectors | Flexible targeting for any website |
| ğŸ“¤ **Multi-Format Export** | JSON, CSV, TXT output options | Compatible with any data pipeline |
| ğŸ’¾ **Rule Management** | Save and reuse extraction rules | Build a library of scrapers |
| âš¡ **Batch Processing** | Run multiple rules simultaneously | Efficient large-scale extraction |

### Advanced Features

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ¨ Visual Element Selector                                      â”‚
â”‚ â”œâ”€ Live page preview                                            â”‚
â”‚ â”œâ”€ Hover-to-highlight elements                                  â”‚
â”‚ â””â”€ Click-to-select interaction                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ“Š Element Categorization                                       â”‚
â”‚ â”œâ”€ Headings (H1-H6)                                             â”‚
â”‚ â”œâ”€ Links, Images, Paragraphs                                    â”‚
â”‚ â”œâ”€ Tables, Lists, Forms                                         â”‚
â”‚ â””â”€ Buttons, Input fields                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ”§ Extraction Rules Engine                                      â”‚
â”‚ â”œâ”€ CSS Selectors (.class, #id, tag)                             â”‚
â”‚ â”œâ”€ XPath expressions                                            â”‚
â”‚ â”œâ”€ Attribute extraction (text, href, src, etc.)                 â”‚
â”‚ â””â”€ Custom selector combinations                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ“¤ Export Pipeline                                              â”‚
â”‚ â”œâ”€ JSON (structured data)                                       â”‚
â”‚ â”œâ”€ CSV (spreadsheet-ready)                                      â”‚
â”‚ â””â”€ TXT (plain text lists)                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Coming Soon

- ğŸ“… Scheduled scraping
- ğŸ” Authentication support
- â˜ï¸ Cloud storage integration
- ğŸ“ˆ Extraction analytics
- ğŸ”— API access
- ğŸ¤– Proxy rotation

---

## ğŸ¯ Use Cases

### Who Uses ScrapeBI?

| Role | Use Case | Example |
|------|----------|---------|
| ğŸ“Š **Data Analyst** | Market research | Extract competitor pricing |
| ğŸ“ˆ **Marketer** | Lead generation | Collect business directories |
| ğŸ›’ **E-commerce** | Product monitoring | Track prices across sites |
| ğŸ“° **Journalist** | Content aggregation | Gather news articles |
| ğŸ“ **Researcher** | Data collection | Extract academic publications |
| ğŸ’¼ **Business** | Competitive intelligence | Monitor industry trends |

### Real-World Examples

```yaml
E-commerce:
  - Product names, prices, descriptions
  - Customer reviews and ratings
  - Inventory availability

Real Estate:
  - Property listings
  - Price history
  - Location data

Job Boards:
  - Job postings
  - Salary information
  - Company details

News & Media:
  - Article headlines
  - Publication dates
  - Author information
```

---

## ğŸš€ Quick Start

### 30-Second Setup

```bash
# 1. Clone repository
git clone https://github.com/RaoHamzaTariq/ScrapeBI.git && cd ScrapeBI

# 2. Install dependencies
pip install -r requirements.txt

# 3. Launch application
python run.py

# âœ… Browser opens automatically at http://localhost:5000
```

### One-Click Launch

| Platform | Command |
|----------|---------|
| ğŸªŸ Windows | Double-click `start.bat` |
| ğŸ macOS | Run `./start.sh` |
| ğŸ§ Linux | Run `./start.sh` |

---

## ğŸ“¦ Installation

### System Requirements

| Requirement | Minimum | Recommended |
|-------------|---------|-------------|
| Python | 3.8 | 3.10+ |
| RAM | 4 GB | 8 GB |
| Storage | 500 MB | 1 GB |
| Browser | Chrome 90+ | Chrome Latest |

### Detailed Installation

#### Windows

```powershell
# Clone repository
git clone https://github.com/RaoHamzaTariq/ScrapeBI.git
cd ScrapeBI

# Create virtual environment (recommended)
python -m venv venv
venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Run application
python run.py
```

#### macOS

```bash
# Install Python (if needed)
brew install python3

# Clone repository
git clone https://github.com/RaoHamzaTariq/ScrapeBI.git
cd ScrapeBI

# Create virtual environment
python3 -m venv venv
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Run application
python3 run.py
```

#### Linux

```bash
# Install dependencies
sudo apt update
sudo apt install python3 python3-pip python3-venv

# Clone repository
git clone https://github.com/RaoHamzaTariq/ScrapeBI.git
cd ScrapeBI

# Create virtual environment
python3 -m venv venv
source venv/bin/activate

# Install packages
pip install -r requirements.txt

# Run application
python3 run.py
```

### Docker Installation (Coming Soon)

```bash
docker pull scrapebi/scrapebi:latest
docker run -p 5000:5000 scrapebi/scrapebi
```

---

## ğŸ’» Usage

### Step-by-Step Guide

#### 1ï¸âƒ£ Enter Website URL

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ”— https://books.toscrape.com/        â±ï¸ 3s  [Scrape] â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### 2ï¸âƒ£ Select Elements Visually

- Navigate to **Visual Selector** tab
- Hover over elements to highlight them
- Click to select desired elements

#### 3ï¸âƒ£ Create Extraction Rule

```
Rule Name: Book Titles
Selector:  .product_pod h3 a
Extract:   Text Content
```

#### 4ï¸âƒ£ Run & Export

- Click **Run All Rules**
- Review results in **Results** tab
- Export as **JSON**, **CSV**, or **TXT**

### Code Examples

#### CSS Selectors

```css
/* Product title */
.product-card h2.title

/* Price */
.price-current

/* All links in navigation */
nav.main-nav a

/* Images with specific class */
img.product-thumbnail

/* Data attributes */
[data-product-id]
```

#### XPath Expressions

```xpath
<!-- All products -->
//div[@class="product"]

<!-- Title within product -->
//div[@class="product"]//h3/a

<!-- Price by class -->
//*[@class="price"]

<!-- Contains text -->
//p[contains(text(), "In stock")]
```

---

## ğŸ”Œ API Reference

### REST API Endpoints

ScrapeBI provides a RESTful API for programmatic access.

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/scrape` | POST | Scrape a website URL |
| `/api/get_elements` | POST | Get detected elements |
| `/api/extract` | POST | Extract data using rules |
| `/api/save_rule` | POST | Save extraction rule |
| `/api/get_rules` | GET | Retrieve all rules |
| `/api/delete_rule/<id>` | DELETE | Delete a rule |
| `/api/export` | POST | Export extracted data |
| `/api/preview_html` | POST | Get preview HTML |

### Example API Usage

```python
import requests

# Scrape a website
response = requests.post('http://localhost:5000/api/scrape', json={
    'url': 'https://example.com',
    'wait_time': 3
})

session_id = response.json()['session_id']

# Extract data
extract_response = requests.post('http://localhost:5000/api/extract', json={
    'session_id': session_id,
    'rule': {
        'selector_type': 'css',
        'selector': 'h1',
        'attribute': 'text'
    }
})

print(extract_response.json()['results'])
```

---

## ğŸ“š Documentation

| Category | Documents |
|----------|-----------|
| ğŸš€ **Getting Started** | [Installation](docs/installation.md) â€¢ [Quick Start](docs/quickstart.md) â€¢ [First Scraper](docs/first-scraper.md) |
| ğŸ“– **User Guides** | [Basic Usage](docs/basic-usage.md) â€¢ [Visual Selector](docs/visual-selector.md) â€¢ [Extraction Rules](docs/extraction-rules.md) |
| ğŸ”§ **Advanced** | [Advanced Selectors](docs/advanced-selectors.md) â€¢ [Dynamic Sites](docs/dynamic-websites.md) â€¢ [Batch Processing](docs/batch-processing.md) |
| ğŸ“‹ **Reference** | [API Reference](docs/api-reference.md) â€¢ [Configuration](docs/configuration.md) â€¢ [Troubleshooting](docs/troubleshooting.md) |

---

## ğŸ—ï¸ Architecture

### System Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        User Interface                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   Visual    â”‚ â”‚   Element   â”‚ â”‚    Extraction Rules     â”‚   â”‚
â”‚  â”‚   Selector  â”‚ â”‚    List     â”‚ â”‚      Management         â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Flask Application                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   Routing   â”‚ â”‚   API       â”‚ â”‚    Data Management      â”‚   â”‚
â”‚  â”‚   Layer     â”‚ â”‚   Endpoints â”‚ â”‚                         â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Selenium WebDriver                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   Chrome    â”‚ â”‚   Page      â”‚ â”‚    Element Location     â”‚   â”‚
â”‚  â”‚   Driver    â”‚ â”‚   Loading   â”‚ â”‚                         â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Data Processing Layer                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   BeautifulSoupâ”‚ â”‚  Pandas    â”‚ â”‚    Export Handlers      â”‚   â”‚
â”‚  â”‚   Parsing   â”‚ â”‚  DataFrames â”‚ â”‚    (JSON/CSV/TXT)       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Technology Stack

```
Frontend                    Backend                     Data
â”œâ”€â”€ TailwindCSS            â”œâ”€â”€ Python 3.8+            â”œâ”€â”€ BeautifulSoup4
â”œâ”€â”€ Vanilla JS             â”œâ”€â”€ Flask 2.3.3            â”œâ”€â”€ Pandas 2.2.0
â”œâ”€â”€ Font Awesome           â”œâ”€â”€ Selenium 4.15.2        â”œâ”€â”€ lxml
â””â”€â”€ Outfit Font            â””â”€â”€ webdriver-manager      â””â”€â”€ requests
```

---

## ğŸ› ï¸ Configuration

### Environment Variables

```bash
# Flask Configuration
FLASK_ENV=development
FLASK_DEBUG=True
FLASK_PORT=5000

# Application Settings
DEFAULT_WAIT_TIME=3
MAX_WAIT_TIME=10
SESSION_TIMEOUT=3600

# Optional: Proxy Settings
PROXY_HOST=localhost
PROXY_PORT=8080
```

### Custom Settings

Edit `app.py` for advanced configuration:

```python
# Change server port
app.run(debug=True, host='0.0.0.0', port=5001)

# Modify session timeout
SESSION_TIMEOUT = 7200  # 2 hours

# Enable/disable headless mode
scraper = SeleniumScraper(headless=True)
```

---

## ğŸ§ª Testing

### Run Tests

```bash
# Install test dependencies
pip install pytest pytest-cov

# Run all tests
pytest

# Run with coverage
pytest --cov=app --cov-report=html

# Run specific test file
pytest tests/test_scraping.py
```

### Test Coverage

```
Name              Stmts   Miss  Cover
-------------------------------------
app.py              450     45    90%
tests/              200     10    95%
-------------------------------------
TOTAL               650     55    92%
```

---

## ğŸ¤ Contributing

We welcome contributions! See our [Contributing Guide](docs/contributing.md) for details.

### How to Contribute

```
1. Fork the repository
2. Create feature branch â†’ git checkout -b feature/amazing-feature
3. Commit changes â†’ git commit -m 'Add amazing feature'
4. Push to branch â†’ git push origin feature/amazing-feature
5. Open Pull Request
```

### Contribution Types

- ğŸ› **Bug Reports** - Create an issue with reproduction steps
- ğŸ’¡ **Feature Requests** - Suggest new features via GitHub Discussions
- ğŸ“ **Documentation** - Improve docs, fix typos, add examples
- ğŸ”§ **Code Contributions** - Fix bugs, add features, improve performance
- ğŸ¨ **Design** - Improve UI/UX, create assets
- ğŸŒ **Translations** - Help localize ScrapeBI

### Development Setup

```bash
# Clone your fork
git clone https://github.com/YOUR_USERNAME/ScrapeBI.git
cd ScrapeBI

# Create development environment
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Install development dependencies
pip install -r requirements.txt
pip install pytest pytest-cov black flake8

# Start development server
python run.py
```

---

## ğŸ“„ License

ScrapeBI is released under the [MIT License](LICENSE).

```
MIT License

Copyright (c) 2026 ScrapeBI

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
```

---

## ğŸ™ Acknowledgments

ScrapeBI is built with love using these amazing open-source projects:

| Project | Purpose | License |
|---------|---------|---------|
| [Flask](https://flask.palletsprojects.com/) | Web Framework | BSD-3 |
| [Selenium](https://www.selenium.dev/) | Browser Automation | Apache-2.0 |
| [TailwindCSS](https://tailwindcss.com/) | Utility-First CSS | MIT |
| [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/) | HTML Parsing | MIT |
| [Pandas](https://pandas.pydata.org/) | Data Manipulation | BSD-3 |
| [Font Awesome](https://fontawesome.com/) | Icon Library | CC BY 4.0 |
| [Outfit Font](https://fonts.google.com/specimen/Outfit) | Typography | OFL-1.1 |

---

## ğŸ“° Changelog

### v1.0.0 (February 25, 2026)

```
âœ¨ New Features
â”œâ”€â”€ Visual element selector with live preview
â”œâ”€â”€ Element categorization (headings, links, images, etc.)
â”œâ”€â”€ CSS and XPath selector support
â”œâ”€â”€ Multi-format export (JSON, CSV, TXT)
â”œâ”€â”€ Rule management and batch processing
â””â”€â”€ Modern dark theme UI with TailwindCSS

ğŸ› Bug Fixes
â”œâ”€â”€ Fixed iframe preview loading issues
â”œâ”€â”€ Improved error handling for dynamic websites
â””â”€â”€ Enhanced selector accuracy

âš¡ Performance
â”œâ”€â”€ Optimized element detection
â””â”€â”€ Faster page scraping with Selenium
```

---

## ğŸ“§ Support

### Get Help

| Resource | Link | Response Time |
|----------|------|---------------|
| ğŸ“– Documentation | [docs/](docs/) | Instant |
| ğŸ› Issues | [GitHub Issues](https://github.com/RaoHamzaTariq/ScrapeBI/issues) | 1-3 days |
| ğŸ’¬ Discussions | [GitHub Discussions](https://github.com/RaoHamzaTariq/ScrapeBI/discussions) | 1-5 days |
| ğŸ“§ Contact | [GitHub Profile](https://github.com/RaoHamzaTariq) | 3-7 days |

### FAQ

<details>
<summary><strong>Is ScrapeBI free to use?</strong></summary>
Yes! ScrapeBI is completely free and open-source under the MIT License.
</details>

<details>
<summary><strong>Can I scrape any website?</strong></summary>
Technically yes, but always respect robots.txt and terms of service. Some websites may block automated access.
</details>

<details>
<summary><strong>Does it work with JavaScript-heavy sites?</strong></summary>
Yes! ScrapeBI uses Selenium which fully renders JavaScript before extraction.
</details>

<details>
<summary><strong>What data formats can I export?</strong></summary>
JSON, CSV, and TXT formats are supported for maximum compatibility.
</details>

---

<p align="center">
  <strong>â­ Enjoy ScrapeBI? Give it a star!</strong>
</p>

<p align="center">
  Made with â¤ï¸ by <a href="https://github.com/RaoHamzaTariq">Rao Hamza Tariq</a>
</p>

<p align="center">
  <a href="#-scrapebi">â†‘ Back to Top â†‘</a>
</p>
